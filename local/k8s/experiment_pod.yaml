apiVersion: v1
kind: Pod
metadata:
  namespace: data-tooling
  name: colossal-ai-temp-a10g
  labels:
    app: colossal-ai-temp-10g
spec:
  volumes:
    - name: colossal-ai-data
      persistentVolumeClaim:
        claimName: colossal-ai-data
    - name: cache-volume
      emptyDir:
        medium: Memory
        sizeLimit: 1Gi        
  containers:
    - name: colossal-ai-temp-10g
      image: 882490700787.dkr.ecr.us-east-1.amazonaws.com/colossalai:main
      ports:
        - containerPort: 5000
        - containerPort: 8888
        - containerPort: 7860
        - containerPort: 8000
        - containerPort: 80
      command: ["/bin/sh"]
      args: ["-c", "tail -f /dev/null"]
      env:
        - name: VERSION
          value: v0.3.0
      resources:
        limits:
          cpu: '8'
          memory: 64Gi
          nvidia.com/gpu: '2'
        requests:
          cpu: '8'
          memory: 64Gi
          nvidia.com/gpu: '2'
      volumeMounts:
        - name: colossal-ai-data
          mountPath: /Workspace
        - name: cache-volume
          mountPath: /dev/shm
      imagePullPolicy: IfNotPresent
  nodeSelector:
    karpenter.sh/provisioner-name: gpu-temp
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: karpenter.sh/provisioner-name
                operator: In
                values:
                  - gpu-temp
  tolerations:
    - key: nvidia.com/gpu-temp
      operator: Equal
      value: 'true'
      effect: NoSchedule
